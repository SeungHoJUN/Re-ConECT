{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Re-ConECT Project\n",
        "\n",
        "text-based Rehabiliation AI for Continuous functional Evaluation & Customized Training\n"
      ],
      "metadata": {
        "id": "JbDRw1QeqQLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Setting up the Required Environment"
      ],
      "metadata": {
        "id": "7Q5OQ7l6qXhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall pyarrow requests\n",
        "!pip install pyarrow==14.0.1 requests==2.31.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHUd7RzIqOQl",
        "outputId": "572cbe9a-8cb2-4862-c8d6-160256b7adde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pyarrow 17.0.0\n",
            "Uninstalling pyarrow-17.0.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/benchmarks/*\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/AWSSDKVariables.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/BuildUtils.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/DefineOptions.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/FindAWSSDKAlt.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/FindAzure.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/FindBrotliAlt.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/FindClangTools.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/FindGTestAlt.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/FindInferTools.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/FindLLVMAlt.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/FindOpenSSLAlt.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/FindProtobufAlt.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/FindPython3Alt.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/FindRapidJSONAlt.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/FindSQLite3Alt.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/FindSnappyAlt.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/FindThriftAlt.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/Findc-aresAlt.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/FindgRPCAlt.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/FindgflagsAlt.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/FindglogAlt.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/FindjemallocAlt.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/Findlibrados.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/Findlz4Alt.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/FindorcAlt.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/Findre2Alt.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/Findutf8proc.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/FindzstdAlt.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/GandivaAddBitcode.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/SetupCxxFlags.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/ThirdpartyToolchain.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/UseCython.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/Usevcpkg.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/aws_sdk_cpp_generate_variables.sh\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/san-config.cmake\n",
            "    /usr/local/lib/python3.10/dist-packages/cmake_modules/snappy.diff\n",
            "    /usr/local/lib/python3.10/dist-packages/examples/dataset/write_dataset_encrypted.py\n",
            "    /usr/local/lib/python3.10/dist-packages/examples/flight/client.py\n",
            "    /usr/local/lib/python3.10/dist-packages/examples/flight/middleware.py\n",
            "    /usr/local/lib/python3.10/dist-packages/examples/flight/server.py\n",
            "    /usr/local/lib/python3.10/dist-packages/examples/parquet_encryption/sample_vault_kms_client.py\n",
            "    /usr/local/lib/python3.10/dist-packages/pyarrow-17.0.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/pyarrow/*\n",
            "    /usr/local/lib/python3.10/dist-packages/scripts/run_emscripten_tests.py\n",
            "    /usr/local/lib/python3.10/dist-packages/scripts/test_imports.py\n",
            "    /usr/local/lib/python3.10/dist-packages/scripts/test_leak.py\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.10/dist-packages/benchmarks/benchmark_sbd_tools.py\n",
            "    /usr/local/lib/python3.10/dist-packages/benchmarks/bigtext_speed_benchmark.py\n",
            "    /usr/local/lib/python3.10/dist-packages/benchmarks/english_golden_rules.py\n",
            "    /usr/local/lib/python3.10/dist-packages/benchmarks/genia.py\n",
            "    /usr/local/lib/python3.10/dist-packages/benchmarks/genia_benchmark.py\n",
            "    /usr/local/lib/python3.10/dist-packages/benchmarks/universal_dependency_sbd.py\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled pyarrow-17.0.0\n",
            "Found existing installation: requests 2.32.3\n",
            "Uninstalling requests-2.32.3:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/requests-2.32.3.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/requests/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled requests-2.32.3\n",
            "Collecting pyarrow==14.0.1\n",
            "  Using cached pyarrow-14.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting requests==2.31.0\n",
            "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow==14.0.1) (1.26.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (2024.7.4)\n",
            "Using cached pyarrow-14.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (38.0 MB)\n",
            "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "Installing collected packages: requests, pyarrow\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 2.21.0 requires pyarrow>=15.0.0, but you have pyarrow 14.0.1 which is incompatible.\n",
            "datasets 2.21.0 requires requests>=2.32.2, but you have requests 2.31.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pyarrow-14.0.1 requests-2.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install -qU guardrails-ai openai langchain_community langchain_experimental langchain-upstage sentence-transformers langchainhub langchain-chroma langchain matplotlib python-dotenv tavily-python ragas faiss-cpu tokenizers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D49M3VChqOSc",
        "outputId": "b0da9c5a-f918-40ae-8317-822238cc243c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: typer 0.12.4 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "PaODxIucqOUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title set API key\n",
        "from pprint import pprint\n",
        "import os\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from IPython import get_ipython\n",
        "\n",
        "upstage_api_key_env_name = 'UPSTAGE_API_KEY'\n",
        "def load_env():\n",
        "    if 'google.colab' in str(get_ipython()):\n",
        "        # Running in Google Colab\n",
        "        from google.colab import userdata\n",
        "        upstage_api_key = userdata.get(upstage_api_key_env_name)\n",
        "        return os.environ.setdefault('UPSTAGE_API_KEY', upstage_api_key)\n",
        "    else:\n",
        "        # Running in local Jupyter Notebook\n",
        "        from dotenv import load_dotenv\n",
        "        load_dotenv()\n",
        "        return os.environ.get(upstage_api_key_env_name)\n",
        "\n",
        "UPSTAGE_API_KEY = load_env()"
      ],
      "metadata": {
        "id": "UfxDdh9CqOWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install -qU  markdownify  langchain-upstage rank_bm25 python-dotenv"
      ],
      "metadata": {
        "id": "0LMyWxreqOY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2JQ1nj1qOa_",
        "outputId": "7b299c89-96b5-4033-c658-088371cb84d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb13PbqwZz_-",
        "outputId": "3c4664dd-9fee-4d73-bd4d-2295729985f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.4.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.43.3\n"
          ]
        }
      ],
      "source": [
        "!pip install -U bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476,
          "referenced_widgets": [
            "29407b9ab74b4adaaab9244116fe1fab",
            "0062ce18f0a64b51a5086423a7abfedc",
            "711e3f9a86114d7b915fbe435be4bc43",
            "618c8c6c5b5c4279b88243398cbfb4f0",
            "82e31c0dfa144299b6a66057a8a19a57",
            "b7c080efa2b248feba9d81f40f21a3e2",
            "b8e18afdafc54757896076403511a070",
            "66de6feb24414517a92ffd71e822f6c7",
            "c2467fea2ecf4c8683dc59e47625e172",
            "56ad7a9602574e56b301631d0831cea6",
            "f384cb019ff44b0d91caac3ffd45d7d9",
            "4cbc1a6ea8ac4f9bac09b555ce3436a2",
            "a98cd561564044839d203995c56f4b8b",
            "54bacf76dbd24fb28f5c2166d9e0504f",
            "4a25d42603db48898c7cb8fdee80c570",
            "f51c35ece540407ca3d85b854eab4518",
            "b9c711a5e88e49409eb6472c18aa20dd",
            "4aa707c8814844899cf149c02758ee62",
            "844189d634074421af918bbf0e8b2d4b",
            "24f6008a02ca47a9a2f6b286f0db8066",
            "813efda40bcc468eb6269bdf33c52602",
            "1da7fff934164a59ac4760f987adfb47",
            "5952d64bf9954d90918addd5754e64a7",
            "ef37b6b4cd234b0e94212d834e1e7ae3",
            "2cc65b0248af4999b3fe1be6a5c0eda4",
            "4a58a3723fe943409c61b0b35dc9e18f",
            "0a8db4992232417abfb3e898515b254a",
            "9c49fa9c84cc4b149e4a42de51174d1a",
            "f5e91f60d1eb46cabf2e383234a5119a",
            "3b02f775dede494cb81e2c7603bbc76c",
            "32f71ab0cb054a3b8034e45d2bbe6426",
            "b927bb55d3dc495c9bc46002f1bf9d6d",
            "351b251c16564f24b76dca0a66bde0cc",
            "00448e091df342d4bbf57a4464343bf8",
            "e7e564a91e53430da99fa06db8575249",
            "455edad0ab98410e9429cc257b8bade5",
            "db843519c458452586c6bce00c68b746",
            "3f9cc9e56c2e4bed950250c531f08c11",
            "08fbaa864c904ea1b9e8620573507da9",
            "316cc63ee9534358b5b1d0ccd939ebbc",
            "3ec144e1999f469cad714e5534abeb0a",
            "8937947c7fee4b1fbbc2176b33911e1f",
            "999c8f94344a4188bba4b6ba1e05fa45",
            "bce2decd29d74a7bab1f343ffd4db0b2",
            "1953c21bcfb840928c8b17753142497d",
            "fcff10873dc04d0bbdef4a7c5dcd9fb0",
            "e2883add596e43bc9a9ec4dfc066104a",
            "1d41f4c442e44c879499b3d3f23d5a5e",
            "a3caadf305d240a294071b04a138bd35",
            "d09bab603fbb4f67a5f31b08e8c9ea38",
            "0ed477209dce48b187846bec5fd7c451",
            "d20180ba82cf473393bf09f757dffec8",
            "639d2357f3d04a9d887945a0d36c3551",
            "ac6f1b2fa10649f7b4f9147d29f7ea2d",
            "d24422b63f194ad4a6bf12edf74c6368",
            "c5e30a6bdc634dce9281ce909cf7bfe9",
            "1c428ee612344bb197ec3795a5d69616",
            "7c4adc3f63144ec8ab7b6da175eb646e",
            "eba03e83d5634c369c40140e7dda7f8e",
            "0b06e1ad8e0f4997a70795a907e3cef9",
            "d4c30916a5034cc4ab635374a0bf04e5",
            "5d95de951fee4eac9bd83a2180cabce0",
            "3d99f6685a4e4ad983c04aa3b4e19c37",
            "be526a370f7e43ec90a82c377c813d69",
            "c37d10fd173e4b5fb843d21633c0f085",
            "3ce2fc256b1a4e8dbf684c6ecd42b337",
            "a31a4664a7c246d589f406ecd15023a2",
            "a2eebc1b4c7b4684917cfbd8531cc1dd",
            "a7b730d282d048a3900afcbc6f7d205e",
            "e9d264add9ed488f856c12b8218fcc24",
            "b3ecb460f583466ba3979f4354a9ed1b",
            "c67ebe605ad144d395a875a58adaac24",
            "7a3798f5ba8d41f4afb05ca1eeee89c6",
            "529ec5b390414c2ebcbcc3e8f97b50c2",
            "49be740f83ed4d73852a497cfd357a63",
            "e438a4e13bee48c8a72a0ed5deb0b9b3",
            "caec071f07b8488c91b8aab3a635f1a0",
            "e35b2a48fc724a6da5a3660cf2522693",
            "bc63c1d60fda41668446917c8bbb4b67",
            "e982b0d6611f40a79f80aeccc07003dc",
            "992d833aff2742aa85c4987df1e08f8a",
            "4ebdc6d972144284923708d959481635",
            "7289018053c849f19abaca78140aebf2",
            "b749123bb4684f19975dd51cc81e4254",
            "c31cfab297234b9e8f1755bf9e846edf",
            "98912a1a23ba4665ba2f33fafdf26fd2",
            "907913df5c5e471f8bf5b7d130585bdd",
            "4ca3c78b23304fa68b0e7ee3bde582f9",
            "2ea32db0154d4920af3ff5377300f827",
            "3dcee89645984a2286f4d539f867803e",
            "c23b7d4d13d5497d88926116eb7f6160",
            "b0a6745128284498a5c5e21545b74c51",
            "4c2a36d04ddf458e821c23947eabd1c1",
            "ff286f2d912841e5add1c4242ce3171f",
            "b020a92b31894d53b97209a23006bfba",
            "44247bb5ea2e48b39c2a82070cb942f2",
            "3039e9aae12146bc8f4878b7a3dd848c",
            "b34be2d8964040e38cf28c8c254192e5",
            "fd964f4d06b74f84b527fc292675be26",
            "6119fd179a6b40f1aeaedf54be7963a4",
            "5ddb4c4a96b74a9a94102fef37794681",
            "934ef4510e164b299cd2906b0c5113ec",
            "f751f9dee5c24eb6b9425c2d7e2b1a0d",
            "2a827b01c36740f5b3947460c03b25c3",
            "4eb1a2b72a1041cf9f29f932b5c33a70",
            "768976f29c9440ec8b14e475e24bd9c9",
            "b1863ceb800545b69da7ed08050211d1",
            "74d887148bf04004a55d5b29adca1225",
            "b5c928047b2a4b8f9a25f98d4480d599",
            "a7d8b958a15b493f85944cd1fee2da88",
            "249564c1252f41dda69a0de88432f054",
            "251b7769a7894693a6ce3442d02ba76d",
            "1f31aa62e9d24b40912c3605ce40798d",
            "fcae069a36074de0bd2b71a74e41f1a9",
            "c37213f7d6cc4b0aa6fa381ce0e77289",
            "afebb358a2484493ad33f20c7a0a825b",
            "a812eb5b70624b04919dca7384a40857",
            "953d3552d5364b349c6b3ef480b90d32",
            "8567b966f68f45d0838ca21a571257f7",
            "a6d1d70928ca4db8992c65ca314e7580",
            "053bd75013914818ba72b61d03b619ed",
            "eeabe797009c4d66adc679ec78d8b984",
            "833bb7c754bd400590b89480dfa8c122",
            "4d1521c56c21445da5616af49533853f",
            "dddc5d8fae9c44ceba183922dbba4c9a",
            "ca064edfb8444353beda41bf0eb9d277",
            "fc1660eb133640c2904e3876ee9d6117",
            "af1c0ee32c4b485a8061c462e8099505",
            "8b4305c915fa46cb91eb31eb8c296bcf",
            "66e5482094534b90b460ec5ea979828d",
            "7fe5fe2d528b4a8aa60faaac4cd940bb",
            "2a4a45428e2e4d11804088a04f4968a4"
          ]
        },
        "id": "lwtUygv6vFX_",
        "outputId": "3dbf7db0-4e1e-450c-b1c3-04ee9289f128"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29407b9ab74b4adaaab9244116fe1fab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cbc1a6ea8ac4f9bac09b555ce3436a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5952d64bf9954d90918addd5754e64a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00448e091df342d4bbf57a4464343bf8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1953c21bcfb840928c8b17753142497d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5e30a6bdc634dce9281ce909cf7bfe9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a31a4664a7c246d589f406ecd15023a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e35b2a48fc724a6da5a3660cf2522693"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ea32db0154d4920af3ff5377300f827"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6119fd179a6b40f1aeaedf54be7963a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "249564c1252f41dda69a0de88432f054"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eeabe797009c4d66adc679ec78d8b984"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum context length: 8192\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "import transformers\n",
        "import torch\n",
        "MY_HF_TOKEN = \"\"\n",
        "\n",
        "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, token=MY_HF_TOKEN)\n",
        "\n",
        "# Load Llama model\n",
        "model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        "    load_in_8bit=True,\n",
        "    token=MY_HF_TOKEN\n",
        ")\n",
        "max_length = model.config.max_position_embeddings\n",
        "print(f\"Maximum context length: {max_length}\")\n",
        "\n",
        "# Create pipeline\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    max_new_tokens=max_length,\n",
        "    do_sample=False,  # Use greedy decoding instead of sampling\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a LangChain LLM\n",
        "chat = HuggingFacePipeline(pipeline=pipeline)"
      ],
      "metadata": {
        "id": "x--T4oQBV457"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. The process differs depending on whether a diagnosis has been received or not.\n"
      ],
      "metadata": {
        "id": "9fymHQQJqjTD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2-1. For patients who have not received a diagnosis:\n",
        "\n",
        "1. An interview is conducted, similar to what is done in an actual rehabilitation hospital.\n",
        "2. A physical examination is conducted.\n",
        "3. When the information from steps 1 and 2 is input into the model, it provides a list of expected diagnoses matching the patient's symptoms and necessary tests. Finally, it determines whether the patient needs to go to the hospital."
      ],
      "metadata": {
        "id": "sT4czBI4rhH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import csv\n",
        "import uuid\n",
        "import tempfile\n",
        "import re\n",
        "from dotenv import load_dotenv\n",
        "from datetime import datetime\n",
        "from dotenv import load_dotenv\n",
        "from langchain_chroma import Chroma\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain_upstage import UpstageEmbeddings\n",
        "from langchain_upstage import UpstageLayoutAnalysisLoader\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema import BaseOutputParser\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Generate a session ID\n",
        "session_id = uuid.uuid4()\n",
        "\n",
        "# Set directory for vector storage\n",
        "persist_directory = \"/content/drive/MyDrive/240814_Llama_RAG/chroma_db\"\n",
        "persist_directory1 = \"/content/drive/MyDrive/240814_Llama_RAG/chroma_db1\"\n",
        "persist_directory2 = \"/content/drive/MyDrive/240814_Llama_RAG/chroma_db2\"\n",
        "\n",
        "# Set the path for saving patient information\n",
        "patient_info_path = \"/content/drive/MyDrive/240814_Llama_RAG/patient_info.json\"\n",
        "\n",
        "class CustomOutputParser(BaseOutputParser):\n",
        "    def parse(self, text: str) -> str:\n",
        "        split_text = text.split('⚑ Answer', 1)\n",
        "        if len(split_text) > 1:\n",
        "            return split_text[1].strip()\n",
        "        else:\n",
        "            return text\n",
        "\n",
        "# Function to process and index PDF files\n",
        "def process_pdf_onlyfile(file_path):\n",
        "    loader = UpstageLayoutAnalysisLoader(\n",
        "        file_path, use_ocr=True, output_type=\"html\"\n",
        "    )\n",
        "    pages = loader.load_and_split()\n",
        "    vectorstore = Chroma.from_documents(pages, UpstageEmbeddings(model=\"solar-embedding-1-large\"), persist_directory=persist_directory)\n",
        "    return vectorstore\n",
        "\n",
        "def create_simple_rag_chain(vectorstore, api_key):\n",
        "    retriever = vectorstore.as_retriever(k=2)\n",
        "\n",
        "    qa_system_prompt = \"\"\"You are a renowned rehabilitation medicine specialist. Check the patient's condition and suggest suspected diagnoses.\n",
        "\n",
        "    1. Check the patient's condition:\n",
        "       a) Chief complaint: <Chief_complaint>\n",
        "       b) History taking:\n",
        "          <History_questions>\n",
        "       c) Physical examinations:\n",
        "          <Physical_examination_questions>\n",
        "\n",
        "    2. Suggest maximum 3 suspected diagnoses based on <History_questions> and <Physical_examination_questions>.\n",
        "       Use the [DIFFERENTIAL DIAGNOSIS] section of the {context}. If no match, suggest \"unspecified neck pain\".\n",
        "\n",
        "    ## Response Format\n",
        "    ⚑ Answer:\n",
        "    ⚑ Evidence per Answer:\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    rag_prompt_custom = PromptTemplate.from_template(template)\n",
        "    output_parser = CustomOutputParser()\n",
        "\n",
        "    rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | rag_prompt_custom | chat | output_parser\n",
        "\n",
        "    return rag_chain\n",
        "\n",
        "# Function to gather user input for patient information\n",
        "def get_user_input():\n",
        "    patient_info = {}\n",
        "    questions = [\n",
        "        (\"patient_chief_complaint\", \"Enter patient's chief complaint: \", lambda x: len(x) > 0),\n",
        "        (\"patient_location\", \"Enter patient's pain location (e.g. Middle, right): \", lambda x: len(x) > 0),\n",
        "        (\"patient_radiation\", \"Is there pain radiation? (Yes/No, and location if Yes): \", lambda x: x.lower() in ['yes', 'no'] or (x.lower().startswith('yes') and len(x) > 3)),\n",
        "        (\"patient_severity\", \"Enter pain severity (mild/moderate/severe): \", lambda x: re.search(r'\\b(extremely\\s+)?(mild|moderate|severe)\\b', x.lower()) is not None),\n",
        "        (\"patient_alleviating_factors\", \"Is pain reduced by lying down? (Yes/No): \", lambda x: x.lower() in ['yes', 'no']),\n",
        "        (\"patient_pain_increase\", \"Pain increase when looking at (aching/opposite/same) side: \", lambda x: x.lower() in ['aching', 'opposite', 'same']),\n",
        "        (\"patient_numbness_or_tingling\", \"Numbness or tingling in arm or hand? (Yes/No): \", lambda x: x.lower() in ['yes', 'no']),\n",
        "        (\"patient_weakness\", \"Weaker or thinner arm than before? (Yes/No): \", lambda x: x.lower() in ['yes', 'no']),\n",
        "        (\"patient_onset_of_pain\", \"When did the pain start? \", lambda x: len(x) > 0),\n",
        "        (\"patient_trauma_history\", \"Did pain start within 1 day of trauma? (Yes/No): \", lambda x: x.lower() in ['yes', 'no']),\n",
        "        (\"patient_lower_back_pain\", \"Pain also in lower back? (Yes/No): \", lambda x: x.lower() in ['yes', 'no']),\n",
        "        (\"patient_morning_stiffness\", \"Stiffness in morning? (Yes/No): \", lambda x: x.lower() in ['yes', 'no']),\n",
        "        (\"patient_leg_symptoms\", \"Leg weakness or pain? (Yes/No): \", lambda x: x.lower() in ['yes', 'no']),\n",
        "        (\"patient_coronary_heart_disease_history\", \"History of coronary heart disease? (Yes/No): \", lambda x: x.lower() in ['yes', 'no']),\n",
        "        (\"patient_weight_loss_appetite\", \"Weight loss or decreased appetite? (Yes/No): \", lambda x: x.lower() in ['yes', 'no']),\n",
        "        (\"patient_pregnancy_breastfeeding\", \"Pregnant or breast feeding? (Yes/No): \", lambda x: x.lower() in ['yes', 'no']),\n",
        "        (\"patient_prolonged_sitting\", \"Prolonged sitting during work? (Yes/No): \", lambda x: x.lower() in ['yes', 'no']),\n",
        "        (\"patient_fever\", \"Fever? (Yes/No): \", lambda x: x.lower() in ['yes', 'no']),\n",
        "        (\"patient_cancer_steroid_history\", \"History of cancer or steroid use? (Yes/No): \", lambda x: x.lower() in ['yes', 'no']),\n",
        "        (\"patient_osteoporosis\", \"Osteoporosis? (Yes/No): \", lambda x: x.lower() in ['yes', 'no']),\n",
        "        (\"patient_age\", \"Patient's age: \", lambda x: x.isdigit() and 0 < int(x) < 120),\n",
        "        (\"patient_alcohol_drug_use\", \"Alcoholic or drug abuse? (Yes/No): \", lambda x: x.lower() in ['yes', 'no']),\n",
        "        (\"patient_HIV_status\", \"HIV? (Yes/No): \", lambda x: x.lower() in ['yes', 'no']),\n",
        "        (\"patient_leg_bending_difficulty\", \"Difficult to bend leg? (Yes/No): \", lambda x: x.lower() in ['yes', 'no']),\n",
        "        (\"patient_urinary_fecal_incontinence\", \"Urinary or fecal incontinence? (Yes/No): \", lambda x: x.lower() in ['yes', 'no']),\n",
        "        (\"patient_shoulder_drooping_or_winging\", \"Shoulder drooping or winging? (Yes/No): \", lambda x: x.lower() in ['yes', 'no']),\n",
        "        (\"patient_upper_neck_tenderness\", \"Tenderness at upper neck? (Yes/No): \", lambda x: x.lower() in ['yes', 'no']),\n",
        "        (\"patient_arm_lift_score\", \"Arm lift against gravity score (0-5): \", lambda x: x.isdigit() and 0 <= int(x) <= 5),\n",
        "        (\"patient_Babinski_Reflex\", \"Babinski Reflex (positive/negative): \", lambda x: x.lower() in ['positive', 'negative']),\n",
        "        (\"patient_sensation_in_arms\", \"Sensation difference between arms? (Yes/No): \", lambda x: x.lower() in ['yes', 'no']),\n",
        "        (\"patient_Spurling_test\", \"Spurling test result (positive/negative): \", lambda x: x.lower() in ['positive', 'negative'])\n",
        "    ]\n",
        "\n",
        "    total_questions = len(questions)\n",
        "\n",
        "    for i, (key, question, validator) in enumerate(questions, 1):\n",
        "        while True:\n",
        "            answer = input(question)\n",
        "            if validator(answer):\n",
        "                patient_info[key] = answer\n",
        "                progress = (i / total_questions) * 100\n",
        "                print(f\"Progress: {progress:.1f}%\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"Invalid input. Please try again.\")\n",
        "\n",
        "    return patient_info\n",
        "\n",
        "# Function to save patient information to a JSON file\n",
        "def save_patient_info(patient_info):\n",
        "    with open(patient_info_path, 'w') as f:\n",
        "        json.dump(patient_info, f)\n",
        "    print(f\"Patient information saved to {patient_info_path}\")\n",
        "\n",
        "# Function to load patient information from a JSON file\n",
        "def load_patient_info():\n",
        "    if os.path.exists(patient_info_path):\n",
        "        with open(patient_info_path, 'r') as f:\n",
        "            return json.load(f)\n",
        "    return None\n",
        "\n",
        "# Function to create history questions based on patient information\n",
        "def create_history_questions(patient_info):\n",
        "    return \"\\n\".join([\n",
        "        f\"- Location (e.g. upper-lower, left-right): {patient_info['patient_location']}\",\n",
        "        f\"- Radiation (include radiating location): {patient_info['patient_radiation']}\",\n",
        "        f\"- Severity (severe/moderate/mild): {patient_info['patient_severity']}\",\n",
        "        f\"- Pain reduced by recumbency (lying down): {patient_info['patient_alleviating_factors']}\",\n",
        "        f\"- More painful when looking at aching side vs opposite side vs same: {patient_info['patient_pain_increase']}\",\n",
        "        f\"- Numbness or tingling in arm or hand: {patient_info['patient_numbness_or_tingling']}\",\n",
        "        f\"- Weaker or thinner arm than before: {patient_info['patient_weakness']}\",\n",
        "        f\"- When did the pain start: {patient_info['patient_onset_of_pain']}\",\n",
        "        f\"- Did the pain start within 1 day of a trauma (e.g. traffic accident, lifting): {patient_info['patient_trauma_history']}\",\n",
        "        f\"- Pain also in lower back: {patient_info['patient_lower_back_pain']}\",\n",
        "        f\"- Stiffness in morning: {patient_info['patient_morning_stiffness']}\",\n",
        "        f\"- Leg weakness or pain: {patient_info['patient_leg_symptoms']}\",\n",
        "        f\"- History of coronary heart disease: {patient_info['patient_coronary_heart_disease_history']}\",\n",
        "        f\"- Weight loss or decreased appetite: {patient_info['patient_weight_loss_appetite']}\",\n",
        "        f\"- Pregnant or breast feeding: {patient_info['patient_pregnancy_breastfeeding']}\",\n",
        "        f\"- Prolonged sitting during work: {patient_info['patient_prolonged_sitting']}\",\n",
        "        f\"- Fever: {patient_info['patient_fever']}\",\n",
        "        f\"- History of cancer or steroid use: {patient_info['patient_cancer_steroid_history']}\",\n",
        "        f\"- Osteoporosis: {patient_info['patient_osteoporosis']}\",\n",
        "        f\"- Age: {patient_info['patient_age']}\",\n",
        "        f\"- Alcoholic or drug abuse: {patient_info['patient_alcohol_drug_use']}\",\n",
        "        f\"- HIV: {patient_info['patient_HIV_status']}\",\n",
        "        f\"- Difficult to bend leg (leg spasticity): {patient_info['patient_leg_bending_difficulty']}\",\n",
        "        f\"- Urinary or fecal incontinence: {patient_info['patient_urinary_fecal_incontinence']}\"\n",
        "    ])\n",
        "\n",
        "# Function to create physical examination questions based on patient information\n",
        "def create_physical_exam_questions(patient_info):\n",
        "    return \"\\n\".join([\n",
        "        f\"- Shoulder drooping or winging: {patient_info['patient_shoulder_drooping_or_winging']}\",\n",
        "        f\"- Tenderness at upper neck: {patient_info['patient_upper_neck_tenderness']}\",\n",
        "        f\"- Arm lift against gravity score (0-5): {patient_info['patient_arm_lift_score']}\",\n",
        "        f\"- Babinski Reflex (positive/negative): {patient_info['patient_Babinski_Reflex']}\",\n",
        "        f\"- Sensation difference between arms: {patient_info['patient_sensation_in_arms']}\",\n",
        "        f\"- Spurling test result (positive/negative): {patient_info['patient_Spurling_test']}\"\n",
        "    ])\n",
        "\n",
        "# Function to generate suspected diagnoses\n",
        "def suspected_diagnoses():\n",
        "    uploaded_file_path = \"/content/drive/MyDrive/240814_Llama_RAG/1_Neck_Pain.pdf\"\n",
        "\n",
        "    if os.path.exists(persist_directory):\n",
        "        print(\"Loading the vector store from local storage.\")\n",
        "        vectorstore = Chroma(\n",
        "            persist_directory=persist_directory,\n",
        "            embedding_function=UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
        "        )\n",
        "    else:\n",
        "        print(\"Creating a new vector store.\")\n",
        "        with tempfile.TemporaryDirectory() as temp_dir:\n",
        "            file_path = os.path.join(temp_dir, os.path.basename(uploaded_file_path))\n",
        "            with open(file_path, \"wb\") as f:\n",
        "                f.write(open(uploaded_file_path, \"rb\").read())\n",
        "            vectorstore = process_pdf_onlyfile(file_path)\n",
        "\n",
        "    # Create RAG chain\n",
        "    simple_rag_chain = create_simple_rag_chain(vectorstore, os.getenv(\"UPSTAGE_API_KEY\"))\n",
        "\n",
        "    patient_info = load_patient_info()\n",
        "    if patient_info:\n",
        "        print(\"Found existing patient information. Would you like to use it? (y/n)\")\n",
        "        use_existing = input().lower()\n",
        "        if use_existing != 'y':\n",
        "            patient_info = None\n",
        "\n",
        "    if not patient_info:\n",
        "        patient_info = get_user_input()\n",
        "        save_patient_info(patient_info)\n",
        "    else:\n",
        "        print(\"Using saved patient information.\")\n",
        "\n",
        "    chief_complaint = patient_info[\"patient_chief_complaint\"]\n",
        "    history_questions = create_history_questions(patient_info)\n",
        "    physical_exam_questions = create_physical_exam_questions(patient_info)\n",
        "\n",
        "    qa_human_prompt = f\"\"\"\n",
        "    Chief_complaint:\n",
        "    {chief_complaint}\n",
        "\n",
        "    History_questions:\n",
        "    {history_questions}\n",
        "\n",
        "    Physical_examination_questions:\n",
        "    {physical_exam_questions}\"\"\"\n",
        "\n",
        "    response = simple_rag_chain.invoke({\n",
        "        \"input\": qa_human_prompt,\n",
        "    })\n",
        "\n",
        "    print(\"1: patient's condition and suggest suspected diagnoses\")\n",
        "    print(response)\n",
        "\n",
        "    return response\n",
        "\n",
        "# PDF processing and indexing function\n",
        "def process_pdf(file_path, persist_directory):\n",
        "    if os.path.exists(persist_directory):\n",
        "        print(f\"Loading vector store from local storage: {persist_directory}\")\n",
        "        return Chroma(persist_directory=persist_directory, embedding_function=UpstageEmbeddings(model=\"solar-embedding-1-large\"))\n",
        "    else:\n",
        "        print(f\"Creating a new vector store: {persist_directory}\")\n",
        "        loader = UpstageLayoutAnalysisLoader(\n",
        "            file_path, use_ocr=True, output_type=\"html\"\n",
        "        )\n",
        "        pages = loader.load_and_split()\n",
        "        vectorstore = Chroma.from_documents(pages, UpstageEmbeddings(model=\"solar-embedding-1-large\"), persist_directory=persist_directory)\n",
        "        return vectorstore\n",
        "\n",
        "# Function to create RAG chain\n",
        "def create_rag_chain(vectorstore, system_prompt):\n",
        "    retriever = vectorstore.as_retriever(k=2)\n",
        "\n",
        "    rag_prompt_custom = PromptTemplate.from_template(system_prompt)\n",
        "    output_parser = CustomOutputParser()\n",
        "\n",
        "    rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | rag_prompt_custom | chat | output_parser\n",
        "\n",
        "    return rag_chain\n",
        "\n",
        "# Function to get examination and red flags\n",
        "def get_examination_and_red_flags(suspected_diagnoses):\n",
        "    uploaded_file_path1 = \"/content/drive/MyDrive/240814_Llama_RAG/2_Neck_Pain.pdf\"\n",
        "    uploaded_file_path2 = \"/content/drive/MyDrive/240814_Llama_RAG/6_PTX.pdf\"\n",
        "\n",
        "    vectorstore1 = process_pdf(uploaded_file_path1, persist_directory1)\n",
        "    vectorstore2 = process_pdf(uploaded_file_path2, persist_directory2)\n",
        "\n",
        "    system_prompt1 = \"\"\"You are a renowned rehabilitation medicine specialist. Your task is to evaluate the patient's condition and suggest further examinations.\n",
        "\n",
        "    1. Check the patient's condition:\n",
        "       a) Chief_complaint: <Chief_complaint>\n",
        "       b) History_taking:\n",
        "          <History_questions>\n",
        "       c) Physical_examinations:\n",
        "          <Physical_examination_questions>\n",
        "       d) Suspected_diagnoses:\n",
        "          <Suspected_diagnoses> and <evidence>\n",
        "\n",
        "    2. Suggest further examinations based on symptoms and suspected diagnoses:\n",
        "       Refer to the [Imaging and Other Diagnostic Tests] section in {context}.\n",
        "\n",
        "    ## Response Format\n",
        "    ⚑ Recommended Tests (provide at least 3 if applicable):\n",
        "      1. [Test Name]\n",
        "          - Purpose:\n",
        "          - Expected Results:\n",
        "      2. [Test Name]\n",
        "          - Purpose:\n",
        "          - Expected Results:\n",
        "      3. [Test Name]\n",
        "          - Purpose:\n",
        "          - Expected Results:\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    system_prompt2 = \"\"\"You are a renowned rehabilitation medicine specialist. Your task is to assess the patient's condition and provide appropriate recommendations. Follow these instructions precisely:\n",
        "\n",
        "    1. Assessment Process\n",
        "\n",
        "      a) Carefully review the <History_questions> and <Physical_examination_questions>.\n",
        "      b) Check for the following red flags. Each of these MUST be considered a red flag if present:\n",
        "          - Fever\n",
        "          - Unexplained weight loss\n",
        "          - History of cancer\n",
        "          - History of violent trauma\n",
        "          - History of steroid use\n",
        "          - Osteoporosis\n",
        "          - Age < 20 or Age ≥ 50 (THIS IS CRITICAL)\n",
        "          - Failure to improve with treatment\n",
        "          - History of alcohol or drug abuse\n",
        "          - HIV\n",
        "          - Lower extremity spasticity\n",
        "          - Loss of bowel or bladder function\n",
        "\n",
        "    2. Age Verification (MANDATORY)\n",
        "\n",
        "      - Extract the patient's exact age from the provided information.\n",
        "      - If the age is 50 or above, this MUST be flagged as a red flag, no exceptions.\n",
        "\n",
        "    3. Red Flag Identification Process\n",
        "\n",
        "      - For each piece of information in the patient's history and examination:\n",
        "        - Compare it against the red flag list above\n",
        "        - If it matches any item on the list, it MUST be marked as a red flag\n",
        "      - Double-check the age. If it's 50 or above, ensure it's marked as a red flag\n",
        "\n",
        "    4. Action Steps\n",
        "\n",
        "      a) If ANY red flags are present (including age ≥ 50):\n",
        "          - List ALL identified red flags\n",
        "          - Recommend immediate hospital visit\n",
        "      b) ONLY if NO red flags are present:\n",
        "          - Refer to the {context} guide\n",
        "          - Suggest rehabilitation exercises\n",
        "\n",
        "    5. Final Check\n",
        "\n",
        "      Before providing your answer, verify one last time:\n",
        "      - Is the patient's age 50 or above? If yes, this MUST be listed as a red flag.\n",
        "      - Have you checked for ALL red flags in the list?\n",
        "\n",
        "    ## Response Format\n",
        "\n",
        "    ⚑ Answer:\n",
        "    [Start with whether red flags are present or not. If present, list ALL red flags and recommend hospital visit. If not, provide PTX guide recommendations.]\n",
        "\n",
        "    ⚑ Evidence per Answer:\n",
        "    [List all relevant information from the patient's history and examination, especially age.]\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    rag_chain1 = create_rag_chain(vectorstore1, system_prompt1)\n",
        "    rag_chain2 = create_rag_chain(vectorstore2, system_prompt2)\n",
        "\n",
        "    patient_info = load_patient_info() or get_user_input()\n",
        "    save_patient_info(patient_info)\n",
        "\n",
        "    chief_complaint = patient_info[\"patient_chief_complaint\"]\n",
        "    history_questions = create_history_questions(patient_info)\n",
        "    physical_exam_questions = create_physical_exam_questions(patient_info)\n",
        "\n",
        "    suspected_diagnoses = suspected_diagnoses()\n",
        "    answer_part, evidence_part = suspected_diagnoses.split(\"⚑ Evidence per Answer:\")\n",
        "    diagnoses = [diagnosis.strip() for diagnosis in answer_part.split(\"\\n\") if diagnosis.strip()]\n",
        "    evidence = [ev.strip() for ev in evidence_part.strip().split(\"\\n\") if ev.strip()]\n",
        "\n",
        "    qa_human_prompt1 = f\"\"\"\n",
        "    Chief_complaint:\n",
        "    {chief_complaint}\n",
        "\n",
        "    History_questions:\n",
        "    {history_questions}\n",
        "\n",
        "    Physical_examination_questions:\n",
        "    {physical_exam_questions}\n",
        "\n",
        "    Suspected_diagnoses:\n",
        "    {diagnoses}\n",
        "\n",
        "    Suspected_diagnoses evidence:\n",
        "    {evidence}\"\"\"\n",
        "\n",
        "    response1 = rag_chain1.invoke({\"input\": qa_human_prompt1})\n",
        "\n",
        "    print(\"\\n2: suggest further examinations\")\n",
        "    print(response1)\n",
        "\n",
        "    qa_human_prompt2 = f\"\"\"\n",
        "    History_questions:\n",
        "    {history_questions}\n",
        "\n",
        "    Physical_examination_questions:\n",
        "    {physical_exam_questions}\"\"\"\n",
        "\n",
        "    response2 = rag_chain2.invoke({\"input\": qa_human_prompt2})\n",
        "\n",
        "    print(\"\\n3: provide appropriate recommendations\")\n",
        "    print(response2)\n",
        "\n",
        "    return response2"
      ],
      "metadata": {
        "id": "731zZi5eqOdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-2. For patients who have received a diagnosis:\n",
        "1. The patient's ID is entered.\n",
        "2. If there are previously saved records, they are retrieved. If not, new data is created.\n",
        "3. A current functional assessment is conducted, and a comparison with records from the past 7 days is performed.\n",
        "4. Decreased functions are identified by comparing with previous records, and appropriate exercises are recommended based on these findings.\n",
        "5. The frequency of exercises and weekly goals are presented.\n",
        "6. Current symptoms are analyzed comprehensively to determine the possibility of complications, and the need for a hospital visit is indicated."
      ],
      "metadata": {
        "id": "yFxxgWYJt1k7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In case there is a diagnostic assessment\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def calculate_7day_average(file_path, date=None):\n",
        "    \"\"\"\n",
        "    Calculates the average of data within 7 days from the specified date in the given CSV file.\n",
        "    If the file is empty or contains no valid data, returns a list of zeros.\n",
        "\n",
        "    :param file_path: Path to the CSV file\n",
        "    :param date: Reference date (default: None, uses today's date if None)\n",
        "    :return: List of 7-day average values for each item, or zeros if no data\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, parse_dates=['datetime'])\n",
        "    except pd.errors.EmptyDataError:\n",
        "        return [0] * 17  # Return list of zeros if file is empty\n",
        "\n",
        "    if df.empty or len(df) == 0:\n",
        "        return [0] * 17  # Return list of zeros if DataFrame is empty\n",
        "\n",
        "    if date is None:\n",
        "        date = datetime.now()\n",
        "    elif isinstance(date, str):\n",
        "        date = datetime.strptime(date, \"%Y-%m-%d\")\n",
        "\n",
        "    seven_days_ago = date - timedelta(days=7)\n",
        "\n",
        "    df_recent = df[df['datetime'] > seven_days_ago]\n",
        "\n",
        "    if df_recent.empty:\n",
        "        return [0] * 17  # Return list of zeros if no data within 7 days\n",
        "\n",
        "    averages = []\n",
        "    for item in range(1, 18):\n",
        "        column_name = f'Item {item}'\n",
        "        avg = df_recent[column_name].mean()\n",
        "        averages.append(round(avg, 2) if not pd.isna(avg) else 0)\n",
        "\n",
        "    return averages\n",
        "\n",
        "def input_item_scores(file_path):\n",
        "    \"\"\"\n",
        "    Function to input scores for Items 1 to 17 from the user or load from existing file.\n",
        "\n",
        "    :param file_path: Path to the CSV file\n",
        "    :return: List containing 17 item scores\n",
        "    \"\"\"\n",
        "    today = datetime.now().strftime(\"%-m/%-d/%Y\")  # Format: M/D/YYYY\n",
        "\n",
        "    if os.path.exists(file_path):\n",
        "        df = pd.read_csv(file_path, parse_dates=['datetime'])\n",
        "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "        today_data = df[df['datetime'].dt.strftime(\"%-m/%-d/%Y\") == today]\n",
        "\n",
        "        if not today_data.empty:\n",
        "            latest_scores = today_data.iloc[-1, 1:].tolist()\n",
        "            print(f\"Loaded today's scores ({today}) from existing file.\")\n",
        "            return latest_scores\n",
        "        else:\n",
        "            print(f\"No scores found for today ({today}). Please input current scores.\")\n",
        "    else:\n",
        "        print(\"No existing file found. Please input current scores.\")\n",
        "\n",
        "    scores = []\n",
        "    for i in range(1, 18):\n",
        "        while True:\n",
        "            try:\n",
        "                score = float(input(f\"Enter the score for Item {i}: \"))\n",
        "                scores.append(score)\n",
        "                break\n",
        "            except ValueError:\n",
        "                print(\"Please enter a valid number.\")\n",
        "\n",
        "    # Save the new scores to the CSV file\n",
        "    new_row = [today] + scores\n",
        "    new_df = pd.DataFrame([new_row], columns=['datetime'] + [f'Item {i}' for i in range(1, 18)])\n",
        "\n",
        "    if os.path.exists(file_path):\n",
        "        existing_df = pd.read_csv(file_path)\n",
        "        updated_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
        "        updated_df.to_csv(file_path, index=False, date_format='%-m/%-d/%Y')\n",
        "    else:\n",
        "        new_df.to_csv(file_path, index=False, date_format='%-m/%-d/%Y')\n",
        "\n",
        "    print(f\"Saved today's scores ({today}) to file.\")\n",
        "    return scores\n",
        "\n",
        "def compare_scores(item_scores, average_scores):\n",
        "    \"\"\"\n",
        "    Compare current scores with 7-day averages and identify items with decreased scores.\n",
        "\n",
        "    :param item_scores: List of current scores for items 1-17\n",
        "    :param average_scores: List of 7-day average scores for items 1-17\n",
        "    :return: List of tuples containing (item name, current score, average score) for decreased items\n",
        "    \"\"\"\n",
        "    item_names = [\n",
        "        \"Reach fwd\", \"Reach Up\", \"Reach Down\", \"Lift Up\", \"Push Down\",\n",
        "        \"Wrist Up\", \"Acquire - Release\", \"Grasp Dynamometer\", \"Lateral Pinch\",\n",
        "        \"Pull Weight\", \"Push Weight\", \"Container\", \"Pinch Die\", \"Pencil\",\n",
        "        \"Manipulate (chip)\", \"Push Index\", \"Push Thumb\"\n",
        "    ]\n",
        "\n",
        "    decreased_items = []\n",
        "\n",
        "    for i, (current, average) in enumerate(zip(item_scores, average_scores)):\n",
        "        if current < average:\n",
        "            decreased_items.append(item_names[i])\n",
        "\n",
        "    return decreased_items\n",
        "\n",
        "def get_patient_info(file_path, diagnosis_id):\n",
        "    \"\"\"\n",
        "    Function to get patient information from user input or load from existing file.\n",
        "\n",
        "    :param file_path: Path to the patient info file\n",
        "    :param diagnosis_id: Diagnostic assessment ID\n",
        "    :return: List containing patient information\n",
        "    \"\"\"\n",
        "    if os.path.exists(file_path):\n",
        "        with open(file_path, 'r') as file:\n",
        "            patient_info = file.read().splitlines()\n",
        "        print(f\"Loaded patient information for {diagnosis_id} from existing file.\")\n",
        "        return patient_info\n",
        "\n",
        "    print(f\"No existing patient info found for {diagnosis_id}. Please input patient information.\")\n",
        "    diagnosed_patient = input('diagnosis: ')\n",
        "    patient_disability = input(\"Patient's disability (write your main difficulty): \")\n",
        "    functional_evaluation = \"CUE-T\"\n",
        "    new_symptoms = input(\"Newly acquired symptoms: \")\n",
        "\n",
        "    patient_info = [diagnosed_patient, patient_disability, functional_evaluation, new_symptoms]\n",
        "\n",
        "    # Save the patient info to a file\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write('\\n'.join(patient_info))\n",
        "\n",
        "    return patient_info"
      ],
      "metadata": {
        "id": "9-cNAv5oqOj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set directories for vector stores\n",
        "persist_directory1 = \"/content/drive/MyDrive/240814_Llama_RAG/chroma_db1\"\n",
        "persist_directory2 = \"/content/drive/MyDrive/240814_Llama_RAG/chroma_db2\"\n",
        "persist_directory3 = \"/content/drive/MyDrive/240814_Llama_RAG/chroma_db3\"\n",
        "persist_directory4 = \"/content/drive/MyDrive/240814_Llama_RAG/chroma_db4\"\n",
        "persist_directory5 = \"/content/drive/MyDrive/240814_Llama_RAG/chroma_db5\"\n",
        "\n",
        "def patient_scores():\n",
        "    # Prompt the user to enter the diagnostic assessment ID\n",
        "    diagnosis_id = input(\"Please enter the diagnostic assessment ID: \")\n",
        "    scores_file_path = f'/content/drive/MyDrive/240814_Llama_RAG/{diagnosis_id}.csv'\n",
        "\n",
        "    # Check if the CSV file for the given diagnostic ID exists\n",
        "    if os.path.exists(scores_file_path):\n",
        "        print(f\"Welcome, {diagnosis_id}\")\n",
        "    else:\n",
        "        with open(scores_file_path, 'w', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            headers = ['datetime'] + [f'Item {i}' for i in range(1, 18)]\n",
        "            writer.writerow(headers)\n",
        "        print(f\"{diagnosis_id}.csv file has been created.\")\n",
        "\n",
        "    # Generate today's date in YYYYMMDD format\n",
        "    today_date = datetime.now().strftime(\"%Y%m%d\")\n",
        "\n",
        "    # Append today's date to the patient_info_file_path\n",
        "    patient_info_file_path = f'/content/drive/MyDrive/240814_Llama_RAG/{diagnosis_id}_{today_date}_info.txt'\n",
        "\n",
        "    # Calculate 7-day average\n",
        "    average_scores = calculate_7day_average(scores_file_path)\n",
        "    print(f\"7-day average scores calculated for {diagnosis_id}.\")\n",
        "\n",
        "    # Input current item scores or load from file\n",
        "    current_scores = input_item_scores(scores_file_path)\n",
        "\n",
        "    # Compare scores and identify decreased items\n",
        "    decreased_items = compare_scores(current_scores, average_scores)\n",
        "    print(f\"\\nItems with decreased scores for {diagnosis_id}:\", decreased_items)\n",
        "\n",
        "    # Get patient information or load from file\n",
        "    patient_info = get_patient_info(patient_info_file_path, diagnosis_id)\n",
        "\n",
        "    print(f\"\\nPatient Information for {diagnosis_id}:\")\n",
        "    print(\"diagnosis:\", patient_info[0])\n",
        "    print(\"Disability:\", patient_info[1])\n",
        "    print(\"Functional Evaluation:\", patient_info[2])\n",
        "    print(\"New Symptoms:\", patient_info[3])\n",
        "\n",
        "    return diagnosis_id, decreased_items, patient_info\n",
        "\n",
        "\n",
        "# PDF processing and indexing function\n",
        "def process_pdf(file_path, persist_directory):\n",
        "    if os.path.exists(persist_directory):\n",
        "        print(f\"Loading vector store from local storage: {persist_directory}\")\n",
        "        return Chroma(persist_directory=persist_directory, embedding_function=UpstageEmbeddings(model=\"solar-embedding-1-large\"))\n",
        "    else:\n",
        "        print(f\"Creating a new vector store: {persist_directory}\")\n",
        "        loader = UpstageLayoutAnalysisLoader(\n",
        "            file_path, use_ocr=True, output_type=\"html\"\n",
        "        )\n",
        "        pages = loader.load_and_split()\n",
        "        vectorstore = Chroma.from_documents(pages, UpstageEmbeddings(model=\"solar-embedding-1-large\"), persist_directory=persist_directory)\n",
        "        return vectorstore\n",
        "\n",
        "def create_rag_chain(vectorstore, system_prompt):\n",
        "    retriever = vectorstore.as_retriever(k=2)\n",
        "\n",
        "    rag_prompt_custom = PromptTemplate.from_template(system_prompt)\n",
        "    output_parser = CustomOutputParser()\n",
        "\n",
        "    rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | rag_prompt_custom | chat | output_parser\n",
        "\n",
        "    return rag_chain\n",
        "\n",
        "def get_rehabilitation_evaluation():\n",
        "    uploaded_file_path2 = \"/content/drive/MyDrive/240814_Llama_RAG/6_PTX.pdf\"\n",
        "    uploaded_file_path3 = \"/content/drive/MyDrive/240814_Llama_RAG/4_CUE_T_Manual.pdf\"\n",
        "    uploaded_file_path4 = \"/content/drive/MyDrive/240814_Llama_RAG/7_Stroke_Complications.pdf\"\n",
        "    uploaded_file_path5 = \"/content/drive/MyDrive/240814_Llama_RAG/8_Spinal_Cord_Injury_Complications.pdf\"\n",
        "\n",
        "    vectorstore2 = process_pdf(uploaded_file_path2, persist_directory2)\n",
        "    vectorstore3 = process_pdf(uploaded_file_path3, persist_directory3)\n",
        "    vectorstore4 = process_pdf(uploaded_file_path4, persist_directory4)\n",
        "    vectorstore5 = process_pdf(uploaded_file_path5, persist_directory5)\n",
        "\n",
        "    system_prompt1 = \"\"\"You are a renowned rehabilitation medicine specialist. Evaluate physical functions related to patient's diagnosis and disabilities. And suggest anatomical structures.\n",
        "\n",
        "    1. Based on <Patient_disability>, suggest which <Functional_evaluation> is needed for the patient.\n",
        "\n",
        "    2. Suggest anatomical structures used during each item in <ITEMs>.:\n",
        "       Refer to the [INTENT] section in {context}.\n",
        "\n",
        "    ## Response Format\n",
        "    ⚑ Suggest <Functional_evaluation>:\n",
        "      1. CUE T Test\n",
        "          - Evidence: [Brief explanation of why this test is appropriate]\n",
        "    ⚑ Extract anatomical structure:\n",
        "      • [Specific muscle group name]: [specific muscles within that group]\n",
        "          - Evidence: [1-2 sentences explaining the role of these muscles in the test]\n",
        "\n",
        "    Note: Always use 'CUE T Test' as the functional evaluation. Provide concise, specific information for each section. Fill in all bracketed fields, including the specific muscle group name, with relevant content.\n",
        "    \"\"\"\n",
        "\n",
        "    system_prompt2 = \"\"\"You are a renowned rehabilitation medicine specialist. Your task is to analyze the exercise information provided in the {context} and suggest appropriate exercises based on the following:\n",
        "\n",
        "    1. Review the \"Client's aim\" mentioned in the {context} to understand the target area for improvement.\n",
        "\n",
        "    2. Analyze the exercise described in \"Client's instructions\" within the {context} and suggest modifications or additional exercises that:\n",
        "      a) Target the same anatomical structures\n",
        "      b) Help achieve the client's aim\n",
        "      c) Provide variety and progression in the rehabilitation program\n",
        "\n",
        "    3. Consider any anatomical structures mentioned in <ITEMs> and incorporate exercises that address these specific areas.\n",
        "\n",
        "    ## Response Format\n",
        "    ⚑  Item of which the score dropped:\n",
        "    [Item of which the score dropped]\n",
        "\n",
        "    ⚑ Suggested Exercises:\n",
        "      1. Exercise Name:\n",
        "        - Description:\n",
        "        - Target muscles/structures:\n",
        "        - How it supports the client's aim:\n",
        "\n",
        "      2. Exercise Name:\n",
        "        [Repeat format for each suggested exercise, (provide at least 3 if applicable)]\n",
        "\n",
        "    ⚑ Recommended Sets and Repetitions:\n",
        "    [Provide a range for sets and repetitions, considering the information given in the {context}]\n",
        "\n",
        "    ⚑ Recommended Sessions per Week:\n",
        "    [Suggest an appropriate frequency based on the information in the {context}]\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    system_prompt3 = \"\"\"You are a renowned rehabilitation medicine specialist. Your task is to show list of extracted complications recommend hospital visit or not.\n",
        "\n",
        "    1. Get <Newly_acquired_symptoms> and Show list of extracted complications to patient\n",
        "\n",
        "    2. recommend hospital visit if <Newly_acquired_symptoms> indicate certain complications among complications extracted from {context}.\n",
        "\n",
        "    ## Response Format\n",
        "\n",
        "    ⚑ suspected complications\n",
        "      - suspected complications:\n",
        "      - Evidence:\n",
        "\n",
        "    ⚑ Visit nearby hospital: [Yes / No]\n",
        "      - Evidence:\"\"\"\n",
        "\n",
        "    rag_chain1 = create_rag_chain(vectorstore3, system_prompt1)\n",
        "    rag_chain2 = create_rag_chain(vectorstore2, system_prompt2)\n",
        "    rag_chain3 = create_rag_chain(vectorstore4, system_prompt3)\n",
        "    rag_chain4 = create_rag_chain(vectorstore5, system_prompt3)\n",
        "\n",
        "    # Input or load patient information\n",
        "    diagnosis_id, decreased_items, patient_info = patient_scores()\n",
        "\n",
        "    diagnosed_patient = patient_info[0]\n",
        "    patient_disability = patient_info[1]\n",
        "    functional_evaluation = patient_info[2]\n",
        "    ITEMs = decreased_items\n",
        "    newly_acquired_symptoms = patient_info[3]\n",
        "\n",
        "\n",
        "    qa_human_prompt1 = f\"\"\"\n",
        "    Diagnosed_patient:\n",
        "    {diagnosed_patient}\n",
        "\n",
        "    Patient_disability:\n",
        "    {patient_disability}\n",
        "\n",
        "    ITEMs:\n",
        "    {ITEMs}\"\"\"\n",
        "\n",
        "    response1 = rag_chain1.invoke({\"input\": qa_human_prompt1})\n",
        "\n",
        "    print(\"\\n1: Suggest Functional_evaluation and Extract anatomical structures\")\n",
        "    print(response1)\n",
        "\n",
        "    pattern = r'⚑ Extract anatomical structure:.*?(?=⚑|\\Z)'\n",
        "    match = re.search(pattern, response1, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        extracted_text = match.group().strip()\n",
        "        # print(extracted_text)\n",
        "\n",
        "    qa_human_prompt2 = f\"\"\"\n",
        "    Suggest_anatomical_structures:\n",
        "    {extracted_text}\n",
        "\n",
        "    ITEMs:\n",
        "    {ITEMs}\"\"\"\n",
        "\n",
        "    response2 = rag_chain2.invoke({\"input\": qa_human_prompt2})\n",
        "\n",
        "    print(\"\\n2: suggest exercises\")\n",
        "    print(response2)\n",
        "\n",
        "    qa_human_prompt3 = f\"\"\"\n",
        "      Newly_acquired_symptoms:\n",
        "      {newly_acquired_symptoms}\"\"\"\n",
        "\n",
        "    if diagnosed_patient == 'Stroke':\n",
        "\n",
        "      response3 = rag_chain3.invoke({\"input\": qa_human_prompt3})\n",
        "\n",
        "      print(\"\\n3: extracted complications and recommend whether hospital visit\")\n",
        "      print(response3)\n",
        "\n",
        "    elif diagnosed_patient == 'Spinal Cord Injury':\n",
        "      response4 = rag_chain4.invoke({\"input\": qa_human_prompt3})\n",
        "\n",
        "      print(\"\\n3: extracted complications and recommend whether hospital visit\")\n",
        "      print(response4)"
      ],
      "metadata": {
        "id": "RjIBdxX6tHtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_diagnosis():\n",
        "    has_diagnosis = input(\"Do you have a diagnostic assessment? (yes/no): \").lower()\n",
        "\n",
        "    if has_diagnosis == \"yes\":\n",
        "        get_rehabilitation_evaluation()\n",
        "    elif has_diagnosis == \"no\":\n",
        "        get_examination_and_red_flags(suspected_diagnoses)\n",
        "    else:\n",
        "        print(\"Invalid input. Please answer 'yes' or 'no'.\")\n",
        "        check_diagnosis()  # Recursively call the function to get correct input\n",
        "# Execute the function\n",
        "check_diagnosis()"
      ],
      "metadata": {
        "id": "dI1OTt9dUqXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "433fa06b-2c8e-40a1-8f86-bb079ce8e51c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Do you have a diagnostic assessment? (yes/no): yes\n",
            "Loading vector store from local storage: /content/drive/MyDrive/240814_Llama_RAG/chroma_db2\n",
            "Loading vector store from local storage: /content/drive/MyDrive/240814_Llama_RAG/chroma_db3\n",
            "Loading vector store from local storage: /content/drive/MyDrive/240814_Llama_RAG/chroma_db4\n",
            "Loading vector store from local storage: /content/drive/MyDrive/240814_Llama_RAG/chroma_db5\n",
            "Please enter the diagnostic assessment ID: 12345678\n",
            "Welcome, 12345678\n",
            "7-day average scores calculated for 12345678.\n",
            "Loaded today's scores (8/23/2024) from existing file.\n",
            "\n",
            "Items with decreased scores for 12345678: ['Grasp Dynamometer']\n",
            "Loaded patient information for 12345678 from existing file.\n",
            "\n",
            "Patient Information for 12345678:\n",
            "diagnosis: Spinal Cord Injury\n",
            "Disability: Activities using arm\n",
            "Functional Evaluation: CUE-T\n",
            "New Symptoms: headache and excessive sweating\n",
            "\n",
            "1: Suggest Functional_evaluation and Extract anatomical structures\n",
            "⚑ Suggest Functional Evaluation:\n",
            "1. CUE T Test\n",
            "    - Evidence: The CUE T Test is a comprehensive assessment tool that evaluates upper extremity function, including grip strength, which is relevant for patients with spinal cord injury and difficulty using their arms.\n",
            "\n",
            "⚑ Extract anatomical structure:\n",
            "• Muscles involved in grip strength:\n",
            "    - Extensor digitorum communis, extensor carpi radialis brevis, extensor carpi radialis longus, extensor carpi ulnaris, extensor digiti minimi, and the first dorsal interosseous.\n",
            "    - Evidence: These muscles are responsible for extension of the fingers and wrist, which are essential for grasping and holding objects, as measured by a Grasp Dynamometer.\n",
            "\n",
            "2: suggest exercises\n",
            "⚑  Item of which the score dropped:\n",
            "Grasp Dynamometer\n",
            "\n",
            "⚑ Suggested Exercises:\n",
            "1. Exercise Name: Wrist Curl\n",
            "   - Description: The client will sit with their forearms resting on a table or bench, palms facing down. They will then curl their wrists upwards, bringing their hands towards their shoulders, and lower them back down.\n",
            "   - Target muscles/structures: Extensor digitorum communis, extensor carpi radialis brevis, extensor carpi radialis longus, extensor carpi ulnaris, extensor digiti minimi, and the first dorsal interosseous.\n",
            "   - How it supports the client's aim: This exercise directly targets the muscles involved in grip strength, helping to improve overall hand and wrist strength.\n",
            "2. Exercise Name: Finger Grip Strengthener\n",
            "   - Description: The client will use a handheld grip strengthener, squeezing and releasing the device to build finger and hand strength.\n",
            "   - Target muscles/structures: All finger flexors and extensors, as well as the intrinsic hand muscles.\n",
            "   - How it supports the client's aim: This exercise specifically targets the muscles responsible for grip strength, providing a focused strengthening routine.\n",
            "3. Exercise Name: Resistance Band Wrist Curls\n",
            "   - Description: The client will sit with their forearms resting on a table or bench, palms facing down. They will attach a resistance band to a fixed object and hold it in their hands. They will then curl their wrists upwards, bringing their hands towards their shoulders, and lower them back down.\n",
            "   - Target muscles/structures: Extensor digitorum communis, extensor carpi radialis brevis, extensor carpi radialis longus, extensor carpi ulnaris, extensor digiti minimi, and the first dorsal interosseous.\n",
            "   - How it supports the client's aim: This exercise provides additional resistance to the wrist curls, increasing the challenge and promoting further strength gains.\n",
            "\n",
            "⚑ Recommended Sets and Repetitions:\n",
            "For each exercise, the client should perform 2-3 sets of 8-12 repetitions.\n",
            "\n",
            "⚑ Recommended Sessions per Week:\n",
            "The client should perform these exercises 2-3 times per week, allowing for adequate rest and recovery between sessions.\n",
            "\n",
            "3: extracted complications and recommend whether hospital visit\n",
            "⚑ suspected complications\n",
            "  - suspected complications: Autonomic dysreflexia\n",
            "  - Evidence: The patient is experiencing headache and excessive sweating, which are common symptoms of autonomic dysreflexia, a medical emergency that generally occurs in patients with SCI at levels of T6 and above.\n",
            "\n",
            "⚑ Visit nearby hospital: Yes\n",
            "  - Evidence: The patient's symptoms indicate a potential complication among the complications extracted from the binders, which requires immediate medical attention. The patient should visit a nearby hospital for proper evaluation and management.\n"
          ]
        }
      ]
    }
  ]
}